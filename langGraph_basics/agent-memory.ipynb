{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13cd1c3e",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/agent-memory.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239417-lesson-7-agent-with-memory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c451ffd-a18b-4412-85fa-85186824dd03",
   "metadata": {},
   "source": [
    "# Agent memory\n",
    "\n",
    "## Review\n",
    "\n",
    "Previously, we built an agent that can:\n",
    "\n",
    "* `act` - let the model call specific tools \n",
    "* `observe` - pass the tool output back to the model \n",
    "* `reason` - let the model reason about the tool output to decide what to do next (e.g., call another tool or just respond directly)\n",
    "\n",
    "![Screenshot 2024-08-21 at 12.45.32 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab7453080e6802cd1703_agent-memory1.png)\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, we're going extend our agent by introducing memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b4b45b-cbaa-41b1-b3ed-f6b0645be3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0cfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "# import os, getpass\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eff247-a2aa-4f7a-8be1-73dfebfecc63",
   "metadata": {},
   "source": [
    "We'll use [LangSmith](https://docs.smith.langchain.com/) for [tracing](https://docs.smith.langchain.com/concepts/tracing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ef2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _set_env(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f123b-db5d-4816-a6a3-2e4247611512",
   "metadata": {},
   "source": [
    "This follows what we did previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46647bbe-def5-4ea7-a315-1de8d97c8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9092b40-20c4-4872-b0ed-be1b53a15ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "771123a3-91ac-4076-92c0-93bcd69cf048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAD5ALYDASIAAhEBAxEB/8QAHQABAAIDAAMBAAAAAAAAAAAAAAUGBAcIAQIDCf/EAFMQAAEEAQIDAgcJCgsFCQAAAAEAAgMEBQYRBxIhEzEIFCJBUWGUFRcyNlZ0srTTFiNUVXGBkZXR0iU0NThCc3V2gqGzGGRyk7EkM0NSU2KDksH/xAAbAQEBAAMBAQEAAAAAAAAAAAAAAQIDBQQGB//EADMRAQABAgEHCgcAAwAAAAAAAAABAhEDBBIhMUFRkQUUM1JhcaGxwdETFSNigZLwIjLh/9oADAMBAAIRAxEAPwD9U0REBERAREQERVy3du6iu2KOLndRpV3mK1kmsDnuft1jg33G438p5BDSOUAu5jHnRRNfZC2Tlq9WosD7NiKuw9zpXho/zWF91WF/HFD2ln7Vh1dAafrPMjsVXuWTsXWrzfGJnEdxL5N3enz+dZn3K4X8T0PZmfsW22DG2Z4f9NB91WF/HFD2ln7U+6nC/jeh7Sz9qfcrhfxPQ9mZ+xPuWwv4ooezM/Yn0e3wNDOrXK92Pnrzxzs/80Tw4fpC+yr1jh/p+V/aw4yDH2hvy2se3xaZpPn52bE/kO49S8UshdwWQgxuWmdcgnPLUybmta57/wD0pg0Boeepa5oDXbEbNIHNJopqj6c/if7SW3LEiItCCIiAiIgIiICIiAiIgIiICIiCF1nl5sFpbJ3a3L43HCW1+cbt7V3kx7+rmLd1mYTEQ4HEVMfX37KvGGBzju5x87ie8kncknqSSVE8RoHzaLyb42OkfXY22GNG7ndk9suwHnJ5NgFYYJmWYY5YnB8cjQ5rh3EEbgr0TowYtvnyi3nK7FM4i8aNGcKJaEOqM2zHWr/N4rUjglszzBvwi2KJrnkDcbnbYela84k+GToTQmE0TlqFk6lx+qMnHShsUI5nMig5yyebdkT+Z0ZH/c7CRx6AdCRXfCp02bOvNKZyrjNf4/KVKViCvqvQdbx58HMRvXnrBrnOY74Qd0G/Tf0az1LieKN7hBwgz+qtK5XLZPTvECDKWq+Lw7W5CTHMc4tnkqQbhshHe0d27d+8ledHSmp/Cg4X6My8WMzWrIKF18UM745K05FdkwBiM7gwtg5g4ECUtPULK1r4RvDnh3qZuntQ6lix+ZdTjvx1TWnkMsMknZscwsYQ8l2/ktJdsCdtgSuSOMuJ4r8T38Y8TV0zqDGV8qyCXF4/HaaqQ1spVYBIHW7kkZldOGjYRNfzB/kgDc7bG4P6ZzGY8KPR+qb2lc1j8bV4YQUhby2NlgFe6yzyOiLnN2bLyc55d+YtdvtsUG1eBfhP6c48aj1bicPWtVpMJcfDDJPXnaLUDQwGY88TRE7neW9k4l+zdyBv02nqPDtz+Et0SQx8jd4pPPFK0h0bx62vDXD1gLn7wV6OY0hxK414DM6bzWOOR1fkM/Syc9B7aFmtK9gZ2c5HK55B35Qd9gfQV0ZeuxY6jYtzu5YII3SyO9DWjcn9AWVEzFUTTrWGDpTMHUGmcVknNDX2q0cz2jua4tBcPzHcKVVf0BRlxuicJBO0snFVjpGkbFrnDmI29RJVgWeLFMYlUU6ryTrERFqQREQEREBERAREQEREBERAVUx9iPQgZjLhbBgweWhbO4jrt80EpPRgHcxx2BADTs4Dnta9ZI2TRvjkY18bwWua4bgg94IWyivNvTVpiVh5715VY977HVj/AAZayGFZuPvOPtuZC3buDYjuxo9TWj/ILx9xNj5VZ7/nQ/ZLZmYc6q+Me1y0b1oRaqho5V/Fi3pw6pzPufFhIcg09pF2naunljPXs+7Zg6belW0aJsA/GnPH/wCaH7JPh4fX8JLRvWdzgxpc4hrQNySegCqtqZmvJGVKu0uno3h9q2PgWy0gthiP9Jm48t/wSByDmJfyfRnD7HSuByNjIZoDqI8jbfJEfyxAhjvztKsrGNjY1rWhrWjYNA2ACZ1GHpom88Lf34XRGp7IiLzsRERAREQEREBERAREQEREBERAREQEREGuq384bI/3WrfW51sVa6rfzhsj/dat9bnWxUBERAREQEREBERAREQEREBERAREQEREBERAREQa7rbf7QmQ6Hf7lq3Xf/e51sRa6rfzhsj/AHWrfW51sVAREQEREBERAREQEREBERAREQEREBFGZ/OxYCk2Z0T7E8rxDXrRfDmkIJDRv0HQEknoACT3Kuvz2rnOJZjsKxp7muuzOI/P2Q3/AEL0UYFeJGdGrtmy2XVFSPd3WH4Bg/a5vs093dYfgGD9rm+zWzmte+OMFl3RUj3d1h+AYP2ub7NPd3WH4Bg/a5vs05rXvjjBZxnjPD1zNzwjZMYzhTYbqWxHFpk4l+aAMdhlmQlxf2Hdu/Y9OgaTuv0DXNNTgBNS8Ii1xejx+GGZnpdh4n4xKImz7cjrA+9/CMYDdtu/c77lbf8Ad3WH4Bg/a5vs05rXvjjBZd0VI93dYfgGD9rm+zT3d1h+AYP2ub7NOa1744wWXdFSPd3WH4Bg/a5vs17Mz+rmO3fjcLI0d7GXZWk/nMR2/R+1Oa1744wWXVFHYHNw5/HizCx8LmvdFNBKAHwyNOzmO26bg+cEgjYgkEEyK8tVM0zNM60ERFiCIiAiIgIiICIiCna6P8P6QHm8emP5/FZuv+Z/Ss5YGuvjBpD57N9VlWeupHR0d3rKzsERFEERR2odQUdLYexlMlJJFSr8pkfFA+Zw3cGjZjGucepHcCgkURY9fI1LVq1VgtQzWapa2xDHIHPhLm8zQ8Dq3cEEb94O6DIREQEWPj8jUy1RlqjahuVnlwbNXkEjHEEtcA4dOhBB9YKyEGFw+O97Vw8wzAAAH+6Vj/1JVwVO4e/x/WH9sD6nVVxXmyrpZ7o8oWREReVBERAREQEREBERBTddfGDSHz2b6rKs9YGuvjBpD57N9VlWeupHR0d3rKzsa04952TFaWxNCrNlmZPNZevjaUOHtsqS2JDzSGN07muMUZZFIXPaOYAeT1K1Lpq9xCNbi9omnmGUM3im4l+NFrUMmRdXdZDjLCLs8LHh72R7N5mnkdICCRsuiNZaHwmv8VHj87TNuvFOy1C6OaSCWGZm/LJHLG5r43jc7Oa4HqfSqu7we9AyNyLZMG+UZGoyleEt+y8W2MkMrHy7yHtJmvc5wmdvICTs8LVMTMo1Tjsln5cNrTS+Dvar0prh1KrNBiNYZVtuMNM/I+WpdJlP30c0Y3d5LywhjVBao1je01w84hY6K3rjSup6tGlaGLz+UNwxMNtsbrFS4173Oa8ktcOcAdNmtB674r8BdDQ4nK46XCvyEGUijhty5O9ZuWJI43c0bRPNI6RoY7ymhrhynqNj1SDgLoeLEZXGvxM9yDKRxQ3Jr+StWrEscbw+OPt5ZXShjXDcNDgPUpmyNTcSr+odKas1NqHUd3VY0vBcZLRz+kso11bD12Rx80dqhuA/yxIXvcyU8rh8HZYM9ihonP8AhD6hbktQwz+6NCnXkx2Tkll7S1Vp8giZM50LXGWVrWvLfvbDyt5WANW58xwF0Nns5eyt7DSSz35Wz3a7L9mOnbkaAA+aq2QQynYDq9h32G6ys3wX0bqPK5zI5HDC1ZzdZlTItdZmEVljOTkLog8M529mzlkDedvKNnBXNkc+3c5rPQuW4haeu3bmMa/h5kc7BXdqixl7FaxG7kZM2aWKN0LvLd5LHObuwEEEK34mlkcHqrhFG/UufyP3YY+3Dmhbys7mTkUBM2SJnNtXc1zTs6EMPU7knqthv8HvQkjzJLi7c1h9OzQmszZe4+exXsMDJYppXTF8zS1rQBIXcnK0t5SAVZ3aEwT7mm7TqO8+nWvZi39tJ/2cOi7F3Tm2duw7eVv6e/qkUyNceCDiosbwB03JHLblfb7aeQ27ktjZ3bPb5PaOdyN2aDyt2buSdt3EncygNG6DwfD+hao4Cm6hTs2ZLb6/jEkjGyP6u5GvcRG0kb8jNm7knbcnefWURaLDB4e/x/WH9sD6nVVxVO4e/wAf1h/bA+p1VcVoyrpZ7o8oWREReVBERAREQEREBERBTddfGDSHz2b6rKs9ffVeCmzFepNTexmRoT+M1+2JEbzyOY5jyASGua9w32PKeV2zuXY19+Tz8Z5TpDISHzuit1C383NMD/kF08OYrw6YiY0aNMxG2Z297LWmUUBZz2bqQSTS6OyjY2AucfGaZ6fkE+5/IEr53O2YI5m6Ly7WyNDwJJ6jHAEb9WmcEH1HqFszPuj9o9yyfRQnutn/AJGZT2ql9unutn/kZlPaqX26Zn3R+0e5ZNoteRcZK0/ESfQrMJedquCkMhJjfGKnO2AkAO5u25d+oPLvzbHfbbqrR7rZ/wCRmU9qpfbpmfdH7R7lk2ihPdbP/IzKe1Uvt091s/8AIzKe1Uvt0zPuj9o9yybRVuxqfMVLMUM2jsvGZWuc2QzVOz6Fo2L+25Wklw2BILuuwOx2y2ZLUEp5W6QvxO8zp7dUM/OWyuP+RTM+6P2j3SzL4e/x/WH9sD6nVVxULpTBS4OhN41Kya9bmdasuj35A8gN5W79eVrWtaN+/bfYb7KaXgx6orxJmns8IsSIiLzoIiICIiAiIgIiICw8vlIsNjrFyZksrYWOeIq8ZklkIBPKxg6ucdujR1JXrmMtHhqfbvhsWXF7I2QVIXSyvc57WN2aO4buG7js1o3c4taCRi4/CSOvtyWUdBayURnjryQsLGQQPeCGAEnd3KyPmd5yDsGg8oD0r4WTIZBmQy7YJ5K1gz42Fse3iYMXZkk8xD5TzS+WA0BsnIB8Jz5tEQEREH53YfwZ+ONPwv5NbO1BpSXUUbm5uePx+0IX05JXwmsD4uSPIY5u22wG2xX6IrXVb+cNkf7rVvrc62KgIiIMbI46pmMfZoX6sN2jaidDPWsxiSOWNw2cx7TuHNIJBB6EFRXLkcDbHIJ8vj7VqKNkTQwPx8fZ8pdzEgyM52tPXdw7Rx3LQA2eRBjY3JVMzQgvULUN2nYYJIrFd4fHI09xa4dCFkqAyWJt4x9jJYTmksNryBuHdK2GpZldJ2nOTyEskJMg527A9oS8P5WlsjjszTys12GvLzT0puwsxEEOifytcAQfS1zSD3EEEIM5ERAREQEREBERAWDlsxBh2VXTNlebNiOrG2Jhced52BPmAHUkn0ec7A5yr3ECR1bR+RuNnyUHiDW33HER9pakbA9sro2M/p84YWFne4OIHegycJhZIJI8lk+xnz0lZtexPBzCINDnP5I2uJ5QC8jfo5wa3m35RtMLw1wc0EHcHqCvKAiIgIiqOstUXYbtfTmnhHLqa8ztBJK3nhx1fch1qYAjcbgtZHuDK/oOVjZZIwice02uPuZsQ7Sw1tO1asz2HcRTGxNII3bdzuRzXbHrs4HuIWxFEaW0vS0hiGUKRkk8p0s9mw7nmszOO75ZXbDme49SdgPMAAABLoCIiAiIgLAyOGhyVmlYfJYgnqTCaN9ed0fN5LmljwDtIwhzvJeCN9nABzWuGeiCDwOasSztxOWELc9BUjs2fE2v8Xe1z3sDmFw6bmMnkJJbzAbu+EZxV2G3vxDt1fH7buXFwyeIGHau3eaUdqJPO87cpb5g1p86sSAiIgIiICIoXMa209p+0K2TzmOx9kjm7GzaYx+3p5Sd9lnTRVXNqYvK2uml87EIsV5Yi98YkaW88buVzdxtuD5j61WvfS0d8qcR7bH+1UnjNW4Z8b+HeV0lntSYY1bjN4bAtROkqzD4EzNz0c0+jbcFze4lbeb43UnhK5s7li4X8StMamo1sBQ1LFktQ42u6C5j71uE5VhgeIJJLELXbtPOBudgN3j0hX1fnf4AfC6pwV4p8QshqzL4uvLRjZi8dc8aZ2Fxj3875oXE9W7Mj9Y5iDsdwO5/fS0d8qcR7bH+1Ob43UnhJmzuWlFVvfS0d8qcR7bH+1Ruo+NekcBhrF2LM0srOzlbDSpWo3SzyOcGsaPK2aC4jd7iGtG7nFrQSHN8bqTwkzZ3JbWmrX6diqUcdWbktR5Nzosdjy/lDyNueaVwB5IIwQ579j3ta0OkfGx310dpJmlaU7prLsll7snjGRyUjOV9qXYDfl3PIxoAaxgJDWgDcncmvcNJsTbuXMlPqDF53VuQY11x9Gy2RsETSeSCEfCELCXbEgFzi5xALthsFaaqKqJtVFpY6hERYgiIgIiICIiCuw29+Idur4/bdy4uGTxAw7V27zSjtRJ53nblLfMGtPnViWnoPCO4Wya8sMHFnTb4TjoQ2p7r1fFQ/tZPKbLz9ZCNgWb9AGnzrcKAiIgIiIMLNXHY/D3rTAC+CCSVoPpa0kf9FUdJVI62ApSAc09mJk88zur5pHNBc9xPUkk/m7u4Kz6q+LGY+ZzfQKr2mvi5ivmkX0AuhgaMKe9diSREWaCIiAiIgg9awtOmshbb97t0oJLVado8uGVjCWuaeno2I36gkHoSrxRsG3Srzkcplja8gebcbqla0+J2d+YT/wCm5XDDfyPR/qI/ohYY/RUz2z6LsZiIi56CIiAiKm8R9fDR1KGvUayfL2w7sI3/AAYmjvlePO0EgADq4kDoNyN2DhV49cYeHF5kWLMagxmnq7Z8pkKuPiceVrrMrYw4+gbnqfUFW38ZdGsdt7uRO9bYpHD9IatGTmS7ekvXZ5L1+T4dqwQ57vUOgDR1PktAA36ALyvrMPkPCin6lczPZo87l4aA074OekcZ4aE+opLUI4bVpPd2r95fyOsl27avJy77Mk3d1GxY0AncrvJnGPRsh2Gcib63xSNH6S1aMRbfkeTdarjHsXh0xiM5js/V8Zxl+tkK++3a1pWyNB9G4Pf6lnLlqnJPi77b+PsSULzO6eA7E+pw7nt/9rgQt88PNdM1pjZRNGyvlanK21Aw7t678sjfPyu5Xbb9QQ4ddtzw8u5MqySPiUTenxj+3mvUtiIi4gi9VfFjMfM5voFV7TXxcxXzSL6AVh1V8WMx8zm+gVXtNfFzFfNIvoBdHB6Ge/0XYzLr7DKc7qkUU9oRuMMU0hjY9+3khzw1xaCdtyGnbv2PctCcNePGqslw10ZYyeEp5jV+qbdmLGVa+Q7KKSKIvfJLO/sAIWxtby7NbIXeR3lxDegVzzprgdrfSeC0Uac+AnzOir1xuOEtmdsGRo2WuD2zOERdBL5TCC0SAFnn5thJvfQiySeEJJRqZHH39NPh1tUzVfBMwMF0SRTz2Iu2he2wWNHZGIPeXFgc0RvHKSADV+LvF7Onh3xBwl2k/R+sMNWo3Y34vJunZLWmstY2WGcMid8JkjHAtaR6wVm5DgRqnLT39Wz38PDryTUVPPVq0Zldj4mVq5rMrOkLRI4OikmJk5B5TwQzZvXxrDgfq7iJQ1zk8xPhKWpM7j6OJpU6liaWpUrV7BnPPM6Jr3ue57z0jAGzR6Ssf8hY7HG/KXdaahwmntKR5yPT9uOpfYcvFXvvLo45HPgqub98Y1so8pz2cxBDd9lttaB4t8EdVcTMpk4ZKGkC2SUOxOrCZ6+Yw7Nh8BscZ7VzSN2ntmA9N29Ou/WNLWNBcXEDYuPefWs4vtEPrT4nZ35hP/puVww38j0f6iP6IVP1p8Ts78wn/wBNyuGG/kej/UR/RCmP0NPfPlC7GYiIuegiIgLm/WuSdmNe5+y9xcIZxSiB/oMiaAQP8Zkd/iXSC5v1tjXYbXufrPbytnnF2In+myRoJP8A9xIP8K+j5Dzfj1X129YXZKna31dR0FpPKagyPOadCEyvbGAXP8waN+m5JAH5VR9PcbbVzIxY/O6YlwF27i35bGtN1k7LUTG8zmOc1oLHgEEgg9N+qtnE7REfEfQWa03JP4sL8HIybl5uzeCHMcR5wHNG49C1lw94GZbT1l02RxWjcfJBjpKcM+FqSdvPK5hZ2r5HNHJuCd2tDt9z+RfTY1WPGLEYf+v9fw1avywe2E8JizkcVpDNXNGWaGA1DebjW5Dx5knZTuc5o2Zyhzmbtd5R5fgu2B6bx3FHjll8lp7iJT03gLpx2CZLQsairX2xSQWQNiY4wA4hju9wduB12WY3gPnxwe0BpTxzG+6On8zDkbUvaydi+NkkriGHk3LtpG9CAOh6rFzfA3W0DOIeH0/lMHHp3Vk8t0vvdt4zBLIN3sAa0t5XHYc25IHUAleKqcrmi030xui983V3X/PaNucMbc+Q4a6TtWppLNmfEVJJZpnl75HmFhc5zj1JJJJJWxeG+SfiuImH5TtHeEtKUbd4MbpGk/kdGAP+I+lUTQ+En01orT+ItPjks4/H16kroSSwvjja1xaSASNwdtwPyK98N8a/K8Q8PyjeOgJbsp37h2bo2g/ldICP+E+he3KIiMjrivqzxt7rTrdDIiL82VF6q+LGY+ZzfQKr2mvi5ivmkX0ArTmabsjiL1RhAfPBJECfMXNI/wD1VDSVyOxgacIPJZrQsgsQO6Phka0BzHA9QQf0jYjoQuhgacKY7V2JhERZoIiICIiCG1p8Ts78wn/03K4Yb+R6P9RH9EKl60nZ9zl+k3aS5egkq1a7T5c0r2ENa0dT6ydtgASegKvNKualKvATzGKNrN/TsNlhj6MKmO2fRdj7oiLnoIiICp3EfQQ1jRinqvZBl6nMYJH/AAJGn4UTz3hpIB3HVpAOxG7XXFFuwcWvArjEw5tMDliyJcfefRvQSUL7PhVbADXj1jrs4dD5TSQduhXldL5fBY3P1xBk6FbIQg7hlmJsgafSNx0PrCrbuDujXnf3Bgb6mPe0foDtl9Zh8uYU0/UomJ7NPnYtDRiLeXvN6N/EcX/Nk/eXszg9o1h39wa7/VI57h+guIW355k/Vq8PctDRlGKfLX20MbXkyF53/gQDfl9bz3Mb63bD8/Rb64e6GZovGSdrIyxlLXK61YY3Zp235WN8/K3mO2/eS49N9hPYrC4/BVRWxtGtj646iKrE2Nu/5AAs1cPLuU68rj4dMWp8+/2NWoREXEBQuY0Xp/UNgWMpg8dkbAHKJbVSOR4Ho3cCdlNIsqa6qJvTNpNSre9Zoz5J4X9Xxfup71mjPknhf1fF+6rSi3c4xuvPGVvO9Vves0Z8k8L+r4v3U96zRnyTwv6vi/dVpROcY3XnjJed6re9Zoz5J4X9Xxfup71mjPknhf1fF+6rSic4xuvPGS870Rh9H4LT0zpcXhcfjpXN5TJVqsjcR6N2gHb1KXRFpqqqrm9U3lBERYgiIgIiICIiAiIgIiICIiD/2Q==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e830b7ae-3673-4cc6-8627-4740b7b8b217",
   "metadata": {},
   "source": [
    "## Memory\n",
    "\n",
    "Let's run our agent, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596a71a0-1337-44d4-971d-f80c367bd868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_G8A6Qjw32fenpXAzZk91t9Zk)\n",
      " Call ID: call_G8A6Qjw32fenpXAzZk91t9Zk\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The sum of 3 and 4 is 7.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8128c-f4a5-4dee-b20b-3245bd33f6b3",
   "metadata": {},
   "source": [
    "Now, let's multiply by 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b41cc1d7-e6de-4d86-8958-8cf7446f4c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply that by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Please specify the number or value you want to multiply by 2.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Multiply that by 2.\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e65f3c-e1dc-4a62-b8ab-02b33a6ff268",
   "metadata": {},
   "source": [
    "We don't retain memory of 7 from our initial chat!\n",
    "\n",
    "This is because [state is transient](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220) to a single graph execution.\n",
    "\n",
    "Of course, this limits our ability to have multi-turn conversations with interruptions. \n",
    "\n",
    "We can use [persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/) to address this! \n",
    "\n",
    "LangGraph can use a checkpointer to automatically save the graph state after each step.\n",
    "\n",
    "This built-in persistence layer gives us memory, allowing LangGraph to pick up from the last state update. \n",
    "\n",
    "One of the easiest checkpointers to use is the `MemorySaver`, an in-memory key-value store for Graph state.\n",
    "\n",
    "All we need to do is simply compile the graph with a checkpointer, and our graph has memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "637fcd79-3896-42e4-9131-e03b123a0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "react_graph_memory = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff8fc3bf-3999-47cb-af34-06b2b94d7192",
   "metadata": {},
   "source": [
    "When we use memory, we need to specify a `thread_id`.\n",
    "\n",
    "This `thread_id` will store our collection of graph states.\n",
    "\n",
    "Here is a cartoon:\n",
    "\n",
    "* The checkpointer write the state at every step of the graph\n",
    "* These checkpoints are saved in a thread \n",
    "* We can access that thread in the future using the `thread_id`\n",
    "\n",
    "![state.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e0e9f526b41a4ed9e2d28b_agent-memory2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f722a1d6-e73c-4023-86ed-8b07d392278d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_eEN9xelUuBWKILS2X5UT6DNr)\n",
      " Call ID: call_eEN9xelUuBWKILS2X5UT6DNr\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The sum of 3 and 4 is 7.\n"
     ]
    }
   ],
   "source": [
    "# Specify a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "\n",
    "# Run\n",
    "messages = react_graph_memory.invoke({\"messages\": messages},config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a8a16-6bf1-48e2-a889-ae04a37c7a2b",
   "metadata": {},
   "source": [
    "If we pass the same `thread_id`, then we can proceed from from the previously logged state checkpoint! \n",
    "\n",
    "In this case, the above conversation is captured in the thread.\n",
    "\n",
    "The `HumanMessage` we pass (`\"Multiply that by 2.\"`) is appended to the above conversation.\n",
    "\n",
    "So, the model now know that `that` refers to the `The sum of 3 and 4 is 7.`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee38c6ef-8bfb-4c66-9214-6f474c9b8451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_eEN9xelUuBWKILS2X5UT6DNr)\n",
      " Call ID: call_eEN9xelUuBWKILS2X5UT6DNr\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The sum of 3 and 4 is 7.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply that by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_wiTCz2VfrWjNH7YuaetHEFjR)\n",
      " Call ID: call_wiTCz2VfrWjNH7YuaetHEFjR\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 7 by 2 is 14.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Multiply that by 2.\")]\n",
    "messages = react_graph_memory.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d72986c-ff6f-4f81-b585-d268e2710e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
