{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbf2458",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/chain.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238466-lesson-4-chain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "## Review\n",
    "\n",
    "We built a simple graph with nodes, normal edges, and conditional edges.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's build up to a simple chain that combines 4 [concepts](https://python.langchain.com/v0.2/docs/concepts/):\n",
    "\n",
    "* Using [chat messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as our graph state\n",
    "* Using [chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) in graph nodes\n",
    "* [Binding tools](https://python.langchain.com/v0.2/docs/concepts/#tools) to our chat model\n",
    "* [Executing tool calls](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling) in graph nodes \n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55e2e80-a718-4aaf-99b9-371157b34a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "Chat models can use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages), which capture different roles within a conversation. \n",
    "\n",
    "LangChain supports various message types, including `HumanMessage`, `AIMessage`, `SystemMessage`, and `ToolMessage`. \n",
    "\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call. \n",
    "\n",
    "Let's create a list of messages. \n",
    "\n",
    "Each message can be supplied with a few things:\n",
    "\n",
    "* `content` - content of the message\n",
    "* `name` - optionally, a message author \n",
    "* `response_metadata` - optionally, a dict of metadata (e.g., often populated by model provider for `AIMessages`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Shakiba\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Shakiba\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"Shakiba\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Shakiba\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "[Chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) can use a sequence of message as input and support message types, as discussed above.\n",
    "\n",
    "There are [many](https://python.langchain.com/v0.2/docs/concepts/#chat-models) to choose from! Let's work with OpenAI. \n",
    "\n",
    "Let's check that your `OPENAI_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2652d5ec-7602-4220-bc6e-b90783ab287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5",
   "metadata": {},
   "source": [
    "We can load a chat model and invoke it with out list of messages.\n",
    "\n",
    "We can see that the result is an `AIMessage` with specific `response_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d60338-c892-4d04-a83f-878de4a76a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The best places to see orcas (killer whales) in the United States are primarily along the Pacific Northwest coast. Here are some top locations:\\n\\n1. San Juan Islands, Washington\\n   - Known as one of the top orca-watching destinations in the world.\\n   - Peak viewing season is from May to September.\\n   - Many tour operators offer whale-watching trips.\\n\\n2. Puget Sound, Washington\\n   - A prime area for orca sightings, especially around Seattle and Tacoma.\\n   - Regular tours depart from Seattle and Edmonds.\\n\\n3. Vancouver Island, British Columbia (just north of the US border)\\n   - Tofino and Victoria are popular spots.\\n   - The region is part of the Great Bear Rainforest and offers excellent whale-watching opportunities.\\n\\n4. Monterey Bay, California\\n   - Offers seasonal orca sightings, especially during the summer months.\\n   - Several tour operators provide whale-watching excursions.\\n\\n5. Southern California\\n   - Occasionally, orcas are seen off the coast of Los Angeles and San Diego.\\n   - Sightings are less predictable but still possible.\\n\\nTips for a successful trip:\\n- The best time to see orcas is during the warmer months, from late spring to early fall.\\n- Book tours with experienced operators who follow responsible whale-watching guidelines.\\n- Bring binoculars and a camera with a good zoom lens for the best viewing experience.\\n\\nWould you like information on specific tour companies or tips for planning your trip?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 297, 'prompt_tokens': 71, 'total_tokens': 368, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_17d1f82c3e', 'finish_reason': 'stop', 'logprobs': None}, id='run-7e7d0d6d-7c39-4fc3-8c85-e2fc7f3f47bb-0', usage_metadata={'input_tokens': 71, 'output_tokens': 297, 'total_tokens': 368})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 297,\n",
       "  'prompt_tokens': 71,\n",
       "  'total_tokens': 368,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4.1-nano-2025-04-14',\n",
       " 'system_fingerprint': 'fp_17d1f82c3e',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4718bd5c-5314-4405-a164-f1fe912ae306",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Tools are useful whenever you want a model to interact with external systems.\n",
    "\n",
    "External systems (e.g., APIs) often require a particular input schema or payload, rather than natural language. \n",
    "\n",
    "When we bind an API, for example, as a tool we given the model awareness of the required input schema.\n",
    "\n",
    "The model will choose to call a tool based upon the natural language input from the user. \n",
    "\n",
    "And, it will return an output that adheres to the tool's schema. \n",
    "\n",
    "[Many LLM providers support tool calling](https://python.langchain.com/v0.1/docs/integrations/chat/) and [tool calling interface](https://blog.langchain.dev/improving-core-tool-interfaces-and-docs-in-langchain/) in LangChain is simple. \n",
    " \n",
    "You can simply pass any Python `function` into `ChatModel.bind_tools(function)`.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a942b1",
   "metadata": {},
   "source": [
    "Let's showcase a simple example of tool calling!\n",
    " \n",
    "The `multiply` function is our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acef4947-656c-465e-8c47-7e76a8729d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001F9B7D9B810>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F9B7E2B810>, root_client=<openai.OpenAI object at 0x000001F9B7671450>, root_async_client=<openai.AsyncOpenAI object at 0x000001F9B7D9B9D0>, model_name='gpt-4.1-nano', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'Multiply a and b.', 'parameters': {'type': 'object', 'properties': {'a': {'description': 'first int', 'type': 'integer'}, 'b': {'description': 'second int', 'type': 'integer'}}, 'required': ['a', 'b']}}}]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f9dba",
   "metadata": {},
   "source": [
    "If we pass an input - e.g., `\"What is 2 multiplied by 3\"` - we see a tool call returned. \n",
    "\n",
    "The tool call has specific arguments that match the input schema of our function along with the name of the function to call.\n",
    "\n",
    "```\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_X7lxhFEwVe9lC88XYFOoAWJT', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 64, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_17d1f82c3e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6b9ce26d-05fb-4787-a137-d8038ed46cad-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_X7lxhFEwVe9lC88XYFOoAWJT', 'type': 'tool_call'}], usage_metadata={'input_tokens': 64, 'output_tokens': 17, 'total_tokens': 81})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"Shakiba\")])\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_X7lxhFEwVe9lC88XYFOoAWJT',\n",
       "  'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'},\n",
       "  'type': 'function'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.additional_kwargs['tool_calls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac98e104-0a9d-495b-8f8a-43d0f63e348c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 58, 'total_tokens': 68, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_17d1f82c3e', 'finish_reason': 'stop', 'logprobs': None}, id='run-0abe0492-a4b4-4208-aee5-4a4aa5c61609-0', usage_metadata={'input_tokens': 58, 'output_tokens': 10, 'total_tokens': 68})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke([HumanMessage(content=\"Hello world\", name=\"Shakiba\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e",
   "metadata": {},
   "source": [
    "## Using messages as state\n",
    "\n",
    "With these foundations in place, we can now use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages) in our graph state.\n",
    "\n",
    "Let's define our state, `MessagesState`, as a `TypedDict` with a single key: `messages`.\n",
    "\n",
    "`messages` is simply a list of messages, as we defined above (e.g., `HumanMessage`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e",
   "metadata": {},
   "source": [
    "## Reducers\n",
    "\n",
    "Now, we have a minor problem! \n",
    "\n",
    "As we discussed, each node will return a new value for our state key `messages`.\n",
    "\n",
    "But, this new value will [will override](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) the prior `messages` value.\n",
    " \n",
    "As our graph runs, we want to **append** messages to to our `messages` state key.\n",
    " \n",
    "We can use [reducer functions](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) address this.\n",
    "\n",
    "Reducers allow us to specify how state updates are performed.\n",
    "\n",
    "If no reducer function is specified, then it is assumed that updates to the key should *override it* as we saw before.\n",
    " \n",
    "But, to append messages, we can use the pre-built `add_messages` reducer.\n",
    "\n",
    "This ensures that any messages are appended to the existing list of messages.\n",
    "\n",
    "We annotate simply need to annotate our `messages` key with the `add_messages` reducer function as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663e574-ba15-46be-a37c-48c8052d693b",
   "metadata": {},
   "source": [
    "Since having a list of messages in graph state is so common, LangGraph has a pre-built [`MessagesState`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)! \n",
    "\n",
    "`MessagesState` is defined: \n",
    "\n",
    "* With a pre-build single `messages` key\n",
    "* This is a list of `AnyMessage` objects \n",
    "* It uses the `add_messages` reducer\n",
    "\n",
    "We'll usually use `MessagesState` because it is less verbose than defining a custom `TypedDict`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ab516ee-eab1-4856-8210-99f1fe499672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c",
   "metadata": {},
   "source": [
    "To go a bit deeper, we can see how the `add_messages` reducer works in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', name='Model', id='1d2aec94-c1c6-4037-890f-7d71076c22c8'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", name='Shakiba', id='bfe72d97-1763-43b8-aa80-ae7eb9df2c59'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', name='Model', id='b51630ab-ea2f-40ed-b784-3ec27f7f7d44')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Shakiba\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2",
   "metadata": {},
   "source": [
    "## Our graph\n",
    "\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "    \n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbc9443d-3090-4efa-b7c4-3dafb3f5e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9266c651-9d58-410b-9202-bc7d6fd7d767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View\n",
    "# https://stackoverflow.com/questions/79575640/mermaid-ink-timeout-error-when-using-short-node-name-in-langgraph-diagram\n",
    "# docker run -p 3000:3000 ghcr.io/jihchi/mermaid.ink\n",
    "# langchain_core/runnables/graph_mermaid.py/\n",
    "# http://localhost:3000\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8909771-7786-47d6-a53d-6bbc3b365737",
   "metadata": {},
   "source": [
    "If we pass in `Hello!`, the LLM responds without any tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba",
   "metadata": {},
   "source": [
    "The LLM chooses to use a tool when it determines that the input or task requires the functionality provided by that tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_ba0c0yBjjhaZWvDnSW3NqJsv)\n",
      " Call ID: call_ba0c0yBjjhaZWvDnSW3NqJsv\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "311fbae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Multiply 2 and 3', id='99bcc9aa-cfcc-46d5-9dcb-9878fcbb4571'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_PPtMnOSVoKsDJd2ydCBladgk', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 58, 'total_tokens': 75, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_eede8f0d45', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-50daa3c5-e729-4c1f-a09e-70a4af57a028-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_PPtMnOSVoKsDJd2ydCBladgk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 17, 'total_tokens': 75})]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0c83ac-215a-4b44-b25b-78f16870f41d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
