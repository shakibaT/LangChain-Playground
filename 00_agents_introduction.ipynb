{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to agents\n",
    "\n",
    "## Objectives\n",
    "By the end of this notebook, you will:\n",
    "- Understand what LangChain agents are.\n",
    "- Learn how to use tools with agents.\n",
    "- Create a simple agent-based application.\n",
    "- How to have more control on agents behavior?\n",
    "\n",
    "\n",
    "\n",
    "## What is agent?\n",
    "One type of LLM application you can build is an agent:\n",
    "\n",
    "<img src=\"1.jpg\" style=\"width:300px;\"/>\n",
    "\n",
    "\n",
    "### Agent's definition in LangChain\n",
    "Agents in LangChain allow dynamic task execution by leveraging large language models (LLMs) \n",
    "to decide which actions to take and in what order. The core idea of agents is to use a language model to choose a sequence of actions to take. In chains, a sequence of actions is hardcoded (in code). In agents, a language model is used as a reasoning engine to determine which actions to take and in which order. More technically, LangChain Agent is a framework that leverages language models (LLMs) to perform dynamic tasks by interacting with external tools and memory systems. These agents allow flexible decision-making based on user inputs, using a reasoning loop to analyze, decide, act, and repeat until the task is completed. LangChain agents utilize the ReAct framework, which combines reasoning and acting iteratively to tackle complex tasks.\n",
    "\n",
    "[Andrew Ng](https://x.com/AndrewYNg/status/1801295202788983136?ref=blog.langchain.dev) highlights a similar inclusive approach in machine learning and agentic systems. He notes that the field of machine learning has always welcomed diverse contributions, and similarly, when thinking about agentic systems, it's more useful to view them on a spectrum. Instead of debating whether something qualifies as a true \"agent,\" systems can be seen as being \"agent-like\" to varying degrees, allowing for more flexibility and creativity in development. This inclusive mindset encourages newcomers to build simple agentic workflows and iteratively make their systems more sophisticated, a perspective that aligns with how LangChain supports the development and evolution of agent-based systems.\n",
    "\n",
    "### Key Components of an agentic application:\n",
    "* Tools: These enable agents to access external data sources or perform computations (e.g., using APIs, querying databases, or running Python code).\n",
    "* Memory: Provides context by storing past interactions. This memory can be short-term (e.g., recent actions) or long-term (retrieving relevant historical data for current tasks).\n",
    "\n",
    "### How Agents Work?\n",
    "Agents follow a reasoning loop where they:\n",
    "\n",
    "1. Analyze the user's query.\n",
    "2. Decide the next action (e.g., which tool to use).\n",
    "3. Observe the results.\n",
    "4. Repeat this process until the task is complete.\n",
    "5. LangChain agents often employ the ReAct framework, which interweaves reasoning and acting steps iteratively for complex decision-making.\n",
    "\n",
    "\n",
    "LangChain continues to refine agent functionality, integrating innovations like multi-agent collaboration and enhanced memory systems to tackle more sophisticated challenges.\n",
    "\n",
    "For a deeper dive, explore the [LangChain blog post](https://blog.langchain.dev/what-is-an-agent/) and related resources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Introduction to Agents\n",
    "\n",
    "Now that you understand the definition of an agent, let’s dive into building our first agents using LangChain. Agents are powerful constructs that dynamically decide the sequence of actions required to achieve a goal by reasoning through tasks and utilizing tools effectively. Before jumping into implementation, it’s crucial to understand the key components of LangChain agents:\n",
    "\n",
    "\n",
    "\n",
    "### Key Components of Agents in LangChain\n",
    "1. Schema\n",
    "    * AgentAction: Represents the action an agent decides to take, such as calling a specific tool. It includes the name of the tool and the corresponding input required to execute the action.\n",
    "    * AgentFinish: Marks the conclusion of the agent's task. It specifies the final output produced by the agent when it determines no further actions are necessary.\n",
    "    * Intermediate Steps: These are the sequence of actions and observations recorded during the agent’s reasoning process. This log provides visibility into the agent's decision-making, making it easier to debug or understand its behavior.\n",
    "\n",
    "2. Agent:\n",
    "The Agent encapsulates the reasoning and decision-making process of the system. It operates by:\n",
    "\n",
    "    * Taking inputs like user queries and context.\n",
    "    * Producing outputs after reasoning through the task, which could involve calling tools and processing intermediate results.\n",
    "\n",
    "3. AgentExecutor:\n",
    "The AgentExecutor is the operational engine that drives the agent. It manages the reasoning loop, which includes:\n",
    "\n",
    "    * Deciding the next action based on observations and context.\n",
    "    * Executing the chosen action.\n",
    "    * Observing the result and feeding it back into the reasoning process.\n",
    "This loop continues until the agent reaches a conclusion or a defined stopping condition.\n",
    "\n",
    "4. Tools:\n",
    "Tools are external resources or functions that agents use to accomplish specific tasks. Each tool has:\n",
    "\n",
    "    * A name: To identify it within the system.\n",
    "    * A description: Explains its functionality to the agent.\n",
    "    * Input/output handling: Defines how the tool processes data and returns results.\n",
    "Examples of tools include search engines, APIs, computational libraries, and custom business logic integrations.\n",
    "\n",
    "For more details and specific code examples, you can explore the [LangChain Agents Documentation​](https://python.langchain.com/v0.1/docs/modules/agents/)\n",
    "\n",
    "Lets dive into simple example:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Agent with Python REPL tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing API keys\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "from langchain.agents import AgentExecutor, Tool\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Define tools the agent can use\n",
    "tools = [PythonREPLTool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakiba/Documents/personal/my_content/LangChain-Playground/venv/lib/python3.11/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE PROMPT:\n",
      "input_variables=['agent_scratchpad', 'input', 'instructions'] optional_variables=['chat_history'] input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10caca8e0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10caca8e0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]} partial_variables={'chat_history': []} metadata={'lc_hub_owner': 'langchain-ai', 'lc_hub_repo': 'openai-functions-template', 'lc_hub_commit_hash': 'b4198088b0f11cbe911a9e1cb6546893c00283b6cf0f80ae003b3955efdfe281'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['instructions'], input_types={}, partial_variables={}, template='{instructions}'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
      "PROMPT:\n",
      "input_variables=['agent_scratchpad', 'input'] optional_variables=['chat_history'] input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10caca8e0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10caca8e0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]} partial_variables={'chat_history': [], 'instructions': 'You are an agent designed to write and execute python code to answer questions.\\nYou have access to a python REPL, which you can use to execute python code.\\nIf you get an error, debug your code and try again.\\nOnly use the output of your code to answer the question. \\nYou might know the answer without running any code, but you should still run the code to get the answer.\\nIf it does not seem like you can write code to answer the question, just return \"I don\\'t know\" as the answer.\\n'} metadata={'lc_hub_owner': 'langchain-ai', 'lc_hub_repo': 'openai-functions-template', 'lc_hub_commit_hash': 'b4198088b0f11cbe911a9e1cb6546893c00283b6cf0f80ae003b3955efdfe281'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['instructions'], input_types={}, partial_variables={}, template='{instructions}'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "# Define instructions and prompts\n",
    "instructions = \"\"\"You are an agent designed to write and execute python code to answer questions.\n",
    "You have access to a python REPL, which you can use to execute python code.\n",
    "If you get an error, debug your code and try again.\n",
    "Only use the output of your code to answer the question. \n",
    "You might know the answer without running any code, but you should still run the code to get the answer.\n",
    "If it does not seem like you can write code to answer the question, just return \"I don't know\" as the answer.\n",
    "\"\"\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "print(\"BASE PROMPT:\")\n",
    "print(base_prompt)\n",
    "prompt = base_prompt.partial(instructions=instructions)\n",
    "print(\"PROMPT:\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `{'query': 'def fibonacci(n):\\n    if n <= 1:\\n        return n\\n    else:\\n        return fibonacci(n-1) + fibonacci(n-2)\\n\\nfibonacci(10)'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThe 10th Fibonacci number is 55.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the 10th fibonacci number?',\n",
       " 'output': 'The 10th Fibonacci number is 55.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the agent\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "\n",
    "# Use the agent\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"What is the 10th fibonacci number?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complecated Agents:\n",
    "\n",
    "In practice, building systems that reliably execute on tasks is incredibly challenging. While agents offer dynamic decision-making capabilities, their flexibility can sometimes result in unpredictable or suboptimal behavior, particularly in production environments. As we’ve worked with users to put agents into production, we’ve learned that achieving consistent and accurate outcomes often requires more control and structure.\n",
    "\n",
    "For instance, you might need an agent to always call a specific tool first, ensure a predefined sequence of actions, or use tailored prompts depending on its state or context. This level of precision is difficult to achieve with unstructured agent workflows alone. To address these challenges, LangChain introduces LangGraph, a framework that allows developers to define workflows and decision paths in a more structured and deterministic way.\n",
    "\n",
    "### LangGraph enables users to:\n",
    "\n",
    "* Define Explicit Paths: Establish clear decision-making workflows, ensuring that agents follow specific sequences or conditions.\n",
    "* State-Aware Execution: Adapt prompts and tool usage dynamically based on the agent's state, enabling more context-sensitive behavior.\n",
    "* Blend Flexibility and Control: Combine the adaptability of agents with the reliability of structured logic, making it easier to meet production-grade requirements.\n",
    "\n",
    "By incorporating LangGraph, developers can move beyond purely reactive agents to build systems that are both agentic and reliable, bridging the gap between flexibility and control. This approach ensures that agents not only make intelligent decisions but also adhere to the operational constraints and business logic necessary for robust performance in real-world applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
