{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LangChain Agents\n",
    "\n",
    "This notebook serves as an introduction to LangChain agents. It covers key concepts, practical use cases, and provides a simple implementation to get you started. Agents are a powerful feature of LangChain that allow language models to interact dynamically with tools, external APIs, or custom logic, making them ideal for multi-step tasks and workflows.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Objectives\n",
    "By the end of this notebook, you will:\n",
    "- Understand what LangChain agents are.\n",
    "- Learn how to use tools with agents.\n",
    "- Create a simple agent-based application.\n",
    "\n",
    "\n",
    "\n",
    "## What is agent?\n",
    "One type of LLM application you can build is an agent:\n",
    "\n",
    "<img src=\"images/1.jpg\" style=\"width:300px;\"/>\n",
    "\n",
    "\n",
    "### Agent's definition in LangChain\n",
    "Agents in LangChain allow dynamic task execution by leveraging large language models (LLMs) \n",
    "to decide which actions to take and in what order. The core idea of agents is to use a language model to choose a sequence of actions to take. In chains, a sequence of actions is hardcoded (in code). In agents, a language model is used as a reasoning engine to determine which actions to take and in which order. More technically, LangChain Agent is a framework that leverages language models (LLMs) to perform dynamic tasks by interacting with external tools and memory systems. These agents allow flexible decision-making based on user inputs, using a reasoning loop to analyze, decide, act, and repeat until the task is completed. LangChain agents utilize the ReAct framework, which combines reasoning and acting iteratively to tackle complex tasks.\n",
    "\n",
    "[Andrew Ng](https://x.com/AndrewYNg/status/1801295202788983136?ref=blog.langchain.dev) highlights a similar inclusive approach in machine learning and agentic systems. He notes that the field of machine learning has always welcomed diverse contributions, and similarly, when thinking about agentic systems, it's more useful to view them on a spectrum. Instead of debating whether something qualifies as a true \"agent,\" systems can be seen as being \"agent-like\" to varying degrees, allowing for more flexibility and creativity in development. This inclusive mindset encourages newcomers to build simple agentic workflows and iteratively make their systems more sophisticated, a perspective that aligns with how LangChain supports the development and evolution of agent-based systems.\n",
    "\n",
    "### Key Components of an agentic application:\n",
    "* Tools: These enable agents to access external data sources or perform computations (e.g., using APIs, querying databases, or running Python code).\n",
    "* Memory: Provides context by storing past interactions. This memory can be short-term (e.g., recent actions) or long-term (retrieving relevant historical data for current tasks).\n",
    "\n",
    "\n",
    "### Why Use LangChain Agents?\n",
    "\n",
    "Unlike simple prompts that generate responses, agents bring the following advantages:\n",
    "- **Dynamic Tool Usage**: Agents can call APIs, query databases, or execute Python code.\n",
    "- **Multi-Step Reasoning**: They can break down complex problems and solve them step-by-step.\n",
    "- **Adaptability**: Agents can adjust their actions based on the state of the task or user input.\n",
    "\n",
    "\n",
    "\n",
    "### How Agents Work?\n",
    "Agents follow a reasoning loop where they:\n",
    "\n",
    "1. Analyze the user's query.\n",
    "2. Decide the next action (e.g., which tool to use).\n",
    "3. Observe the results.\n",
    "4. Repeat this process until the task is complete.\n",
    "5. LangChain agents often employ the ReAct framework, which interweaves reasoning and acting steps iteratively for complex decision-making.\n",
    "\n",
    "\n",
    "LangChain continues to refine agent functionality, integrating innovations like multi-agent collaboration and enhanced memory systems to tackle more sophisticated challenges.\n",
    "\n",
    "For a deeper dive, explore the [LangChain blog post](https://blog.langchain.dev/what-is-an-agent/) and related resources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Introduction to Agents\n",
    "\n",
    "Now that you understand the definition of an agent, let’s dive into building our first agents using LangChain. Agents are powerful constructs that dynamically decide the sequence of actions required to achieve a goal by reasoning through tasks and utilizing tools effectively. Before jumping into implementation, it’s crucial to understand the key components of LangChain agents:\n",
    "\n",
    "\n",
    "\n",
    "### Key Components of Agents in LangChain\n",
    "1. Schema\n",
    "    * AgentAction: Represents the action an agent decides to take, such as calling a specific tool. It includes the name of the tool and the corresponding input required to execute the action.\n",
    "    * AgentFinish: Marks the conclusion of the agent's task. It specifies the final output produced by the agent when it determines no further actions are necessary.\n",
    "    * Intermediate Steps: These are the sequence of actions and observations recorded during the agent’s reasoning process. This log provides visibility into the agent's decision-making, making it easier to debug or understand its behavior.\n",
    "\n",
    "2. Agent:\n",
    "The Agent encapsulates the reasoning and decision-making process of the system. It operates by:\n",
    "\n",
    "    * Taking inputs like user queries and context.\n",
    "    * Producing outputs after reasoning through the task, which could involve calling tools and processing intermediate results.\n",
    "\n",
    "3. AgentExecutor:\n",
    "The AgentExecutor is the operational engine that drives the agent. It manages the reasoning loop, which includes:\n",
    "\n",
    "    * Deciding the next action based on observations and context.\n",
    "    * Executing the chosen action.\n",
    "    * Observing the result and feeding it back into the reasoning process.\n",
    "This loop continues until the agent reaches a conclusion or a defined stopping condition.\n",
    "\n",
    "4. Tools:\n",
    "Tools are external resources or functions that agents use to accomplish specific tasks. Each tool has:\n",
    "\n",
    "    * A name: To identify it within the system.\n",
    "    * A description: Explains its functionality to the agent.\n",
    "    * Input/output handling: Defines how the tool processes data and returns results.\n",
    "Examples of tools include search engines, APIs, computational libraries, and custom business logic integrations.\n",
    "\n",
    "For more details and specific code examples, you can explore the [LangChain Agents Documentation​](https://python.langchain.com/v0.1/docs/modules/agents/)\n",
    "\n",
    "Lets dive into simple example:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Agent with Python REPL tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing API keys\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "from langchain.agents import AgentExecutor, Tool\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain import hub\n",
    "# Make sure BaseCache is defined somewhere\n",
    "from langchain.schema.cache import BaseCache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-core==0.3.0\n",
      "  Downloading langchain_core-0.3.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-openai==0.2.0\n",
      "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pydantic==2.10.6\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.11/site-packages (from langchain-core==0.3.0) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.11/site-packages (from langchain-core==0.3.0) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.117 in ./venv/lib/python3.11/site-packages (from langchain-core==0.3.0) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.11/site-packages (from langchain-core==0.3.0) (24.2)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core==0.3.0)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.11/site-packages (from langchain-core==0.3.0) (4.12.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in ./venv/lib/python3.11/site-packages (from langchain-openai==0.2.0) (1.79.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./venv/lib/python3.11/site-packages (from langchain-openai==0.2.0) (0.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic==2.10.6) (0.7.0)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic==2.10.6)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.0) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (3.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (1.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (0.8.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.0) (2024.11.6)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (3.10)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (2.2.3)\n",
      "Downloading langchain_core-0.3.0-py3-none-any.whl (405 kB)\n",
      "Downloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, pydantic-core, pydantic, langchain-core, langchain-openai\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.33.2\n",
      "    Uninstalling pydantic_core-2.33.2:\n",
      "      Successfully uninstalled pydantic_core-2.33.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.11.4\n",
      "    Uninstalling pydantic-2.11.4:\n",
      "      Successfully uninstalled pydantic-2.11.4\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.60\n",
      "    Uninstalling langchain-core-0.3.60:\n",
      "      Successfully uninstalled langchain-core-0.3.60\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 0.2.10\n",
      "    Uninstalling langchain-openai-0.2.10:\n",
      "      Successfully uninstalled langchain-openai-0.2.10\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "instructor 1.7.9 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\n",
      "langgraph 0.2.59 requires langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43, but you have langchain-core 0.3.0 which is incompatible.\n",
      "langchain-text-splitters 0.3.8 requires langchain-core<1.0.0,>=0.3.51, but you have langchain-core 0.3.0 which is incompatible.\n",
      "langchain-community 0.3.8 requires langchain-core<0.4.0,>=0.3.21, but you have langchain-core 0.3.0 which is incompatible.\n",
      "langchain 0.3.25 requires langchain-core<1.0.0,>=0.3.58, but you have langchain-core 0.3.0 which is incompatible.\n",
      "langchain-experimental 0.3.3 requires langchain-core<0.4.0,>=0.3.15, but you have langchain-core 0.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-0.3.0 langchain-openai-0.2.0 pydantic-2.10.6 pydantic-core-2.27.2 tenacity-8.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# We need following versions for this error: PydanticUserError: `OpenAI` is not fully defined; you should define `BaseCache`, then call `OpenAI.model_rebuild()`.\n",
    "! pip install langchain-core==0.3.0 langchain-openai==0.2.0 pydantic==2.10.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Define tools the agent can use\n",
    "tools = [PythonREPLTool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE PROMPT:\n",
      "input_variables=['agent_scratchpad', 'input', 'instructions'] optional_variables=['chat_history'] input_types={'chat_history': typing.List[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x113c085e0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': typing.List[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x113c085e0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]} partial_variables={'chat_history': []} metadata={'lc_hub_owner': 'langchain-ai', 'lc_hub_repo': 'openai-functions-template', 'lc_hub_commit_hash': 'b4198088b0f11cbe911a9e1cb6546893c00283b6cf0f80ae003b3955efdfe281'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['instructions'], input_types={}, partial_variables={}, template='{instructions}'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
      "PROMPT:\n",
      "input_variables=['agent_scratchpad', 'input'] optional_variables=['chat_history'] input_types={'chat_history': typing.List[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x113c085e0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': typing.List[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x113c085e0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]} partial_variables={'chat_history': [], 'instructions': 'You are an agent designed to write and execute python code to answer questions.\\nYou have access to a python REPL, which you can use to execute python code.\\nIf you get an error, debug your code and try again.\\nOnly use the output of your code to answer the question. \\nYou might know the answer without running any code, but you should still run the code to get the answer.\\nIf it does not seem like you can write code to answer the question, just return \"I don\\'t know\" as the answer.\\n'} metadata={'lc_hub_owner': 'langchain-ai', 'lc_hub_repo': 'openai-functions-template', 'lc_hub_commit_hash': 'b4198088b0f11cbe911a9e1cb6546893c00283b6cf0f80ae003b3955efdfe281'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['instructions'], input_types={}, partial_variables={}, template='{instructions}'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "# Define instructions and prompts\n",
    "instructions = \"\"\"You are an agent designed to write and execute python code to answer questions.\n",
    "You have access to a python REPL, which you can use to execute python code.\n",
    "If you get an error, debug your code and try again.\n",
    "Only use the output of your code to answer the question. \n",
    "You might know the answer without running any code, but you should still run the code to get the answer.\n",
    "If it does not seem like you can write code to answer the question, just return \"I don't know\" as the answer.\n",
    "\"\"\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "print(\"BASE PROMPT:\")\n",
    "print(base_prompt)\n",
    "prompt = base_prompt.partial(instructions=instructions)\n",
    "print(\"PROMPT:\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `{'query': 'def fibonacci(n):\\n    if n <= 1:\\n        return n\\n    else:\\n        return fibonacci(n-1) + fibonacci(n-2)\\n\\nfibonacci(10)'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThe 10th Fibonacci number is 55.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the 10th fibonacci number?',\n",
       " 'output': 'The 10th Fibonacci number is 55.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the agent\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "\n",
    "# Use the agent\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"What is the 10th fibonacci number?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Agent Types in LangChain\n",
    "\n",
    "LangChain has historically supported several agent types, each designed to handle specific use cases for reasoning and action. Here's a brief overview of the primary types:\n",
    "\n",
    "1. `ZERO_SHOT_REACT_DESCRIPTION`: \n",
    "\n",
    "    * Description: An agent that uses a zero-shot approach to reason and act based on a single input prompt. It dynamically decides the next step, whether reasoning or invoking tools, without relying on examples.\n",
    "    * Use Case: Best for quick, one-step tasks that require dynamic decision-making.\n",
    "\n",
    "2. `REACT_DOCSTORE`:\n",
    "\n",
    "    * Description: Combines reasoning and action for tasks specifically focused on document retrieval and question answering using a document store.\n",
    "    * Use Case: Useful in scenarios where knowledge is confined to a local document repository.\n",
    "\n",
    "3. `SELF_ASK_WITH_SEARCH`: \n",
    "\n",
    "    * Description: An agent designed to iteratively decompose a question into smaller sub-questions, answer them, and use search capabilities for external data when needed.\n",
    "    * Use Case: Suited for complex queries requiring external data retrieval and stepwise reasoning.\n",
    "\n",
    "4. `CONVERSATIONAL_REACT_DESCRIPTION`: \n",
    "\n",
    "    * Description: A conversational variant of the zero-shot agent that incorporates context from prior interactions to provide continuity in dialogues.\n",
    "    * Use Case: Ideal for chatbot-like scenarios where maintaining context across multiple turns is essential.\n",
    "\n",
    "5. `CHAT_ZERO_SHOT_REACT_DESCRIPTION`: \n",
    "\n",
    "    * Description: A zero-shot React agent specifically designed for chat-based contexts. It leverages a single prompt to reason and act dynamically, tailored to conversational workflows.\n",
    "    * Use Case: Ideal for tasks where a chat interface is the primary interaction medium and tool usage is minimal or straightforward.\n",
    "\n",
    "6. `CHAT_CONVERSATIONAL_REACT_DESCRIPTION`:\n",
    "\n",
    "    * Description: A chat-oriented React agent that incorporates conversational memory, allowing it to consider prior interactions when making decisions or generating responses. This enhances continuity in dialogues and supports more nuanced conversations.\n",
    "    * Use Case: Best suited for chatbot applications or multi-turn interactions where maintaining the conversation’s context is essential.\n",
    "\n",
    "7. `STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION`: \n",
    "    * Description: This agent is a variant of the zero-shot React agent specifically optimized for chat-based models. It excels in invoking tools that require multiple structured inputs, ensuring accurate and well-formatted interactions.\n",
    "    * Use Case: Suitable for workflows where tools or APIs have multi-field inputs, such as data retrieval systems or complex computations.\n",
    "\n",
    "8. `OPENAI_FUNCTIONS`: \n",
    "\n",
    "    * Description: Designed to work with OpenAI’s fine-tuned models that support functions (e.g., for specific APIs or structured outputs).\n",
    "    * Use Case: Helpful in integrating OpenAI’s functionality seamlessly into workflows.\n",
    "\n",
    "9. `OPENAI_MULTI_FUNCTIONS`:\n",
    "\n",
    "    * Description: An advanced variant of OPENAI_FUNCTIONS capable of managing multiple functions within the same workflow.\n",
    "    * Use Case: Useful for sophisticated applications requiring interaction with several APIs or tools.\n",
    "\n",
    "\n",
    "For more information see [LangChain repo](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/agent_types.py). These older agent types have been deprecated in favor of a more streamlined and robust set of agent types that leverage standardized approaches.\n",
    "Also, the LangChain documentation categorizes agent types based on features like intended model type (chat models or LLMs), support for chat history, multi-input tools, parallel function calling, and additional model parameters. It provides guidance on when to use each type, such as tool-calling agents for specific functionalities or legacy OpenAI tools for older models. For more detailed descriptions of each agent type, refer to the original page [here](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/).\n",
    "\n",
    "Let's discover agents with more examples!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakiba/Documents/personal/my_content/LangChain-Playground/venv/lib/python3.11/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use a search engine to find the answer\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"weather in New York\"\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New York', 'region': 'New York', 'country': 'United States of America', 'lat': 40.7142, 'lon': -74.0064, 'tz_id': 'America/New_York', 'localtime_epoch': 1747724470, 'localtime': '2025-05-20 03:01'}, 'current': {'last_updated_epoch': 1747724400, 'last_updated': '2025-05-20 03:00', 'temp_c': 10.4, 'temp_f': 50.7, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 11.2, 'wind_kph': 18.0, 'wind_degree': 318, 'wind_dir': 'NW', 'pressure_mb': 1014.0, 'pressure_in': 29.94, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 58, 'cloud': 0, 'feelslike_c': 8.1, 'feelslike_f': 46.5, 'windchill_c': 6.2, 'windchill_f': 43.2, 'heatindex_c': 8.4, 'heatindex_f': 47.1, 'dewpoint_c': 4.7, 'dewpoint_f': 40.5, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 15.3, 'gust_kph': 24.6}}\"}]\u001b[0m\u001b[32;1m\u001b[1;3mI should parse the JSON and extract the current temperature\n",
      "Action: Parse JSON\n",
      "Action Input: {'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New York', 'region': 'New York', 'country': 'United States of America', 'lat': 40.7142, 'lon': -74.0064, 'tz_id': 'America/New_York', 'localtime_epoch': 1747724470, 'localtime': '2025-05-20 03:01'}, 'current': {'last_updated_epoch': 1747724400, 'last_updated': '2025-05-20 03:00', 'temp_c': 10.4, 'temp_f': 50.7, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 11.2, 'wind_kph': 18.0, 'wind_degree': 318, 'wind_dir': 'NW', 'pressure_mb': 1014.0, 'pressure_in': 29.\u001b[0mParse JSON is not a valid tool, try one of [tavily_search_results_json].\u001b[32;1m\u001b[1;3mI should use a search engine to find the answer\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"weather in New York\"\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New York', 'region': 'New York', 'country': 'United States of America', 'lat': 40.7142, 'lon': -74.0064, 'tz_id': 'America/New_York', 'localtime_epoch': 1747724470, 'localtime': '2025-05-20 03:01'}, 'current': {'last_updated_epoch': 1747724400, 'last_updated': '2025-05-20 03:00', 'temp_c': 10.4, 'temp_f': 50.7, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 11.2, 'wind_kph': 18.0, 'wind_degree': 318, 'wind_dir': 'NW', 'pressure_mb': 1014.0, 'pressure_in': 29.94, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 58, 'cloud': 0, 'feelslike_c': 8.1, 'feelslike_f': 46.5, 'windchill_c': 6.2, 'windchill_f': 43.2, 'heatindex_c': 8.4, 'heatindex_f': 47.1, 'dewpoint_c': 4.7, 'dewpoint_f': 40.5, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 15.3, 'gust_kph': 24.6}}\"}]\u001b[0m\u001b[32;1m\u001b[1;3mI should extract the current temperature\n",
      "Action: Extract current temperature\n",
      "Action Input: [{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New York', 'region': 'New York', 'country': 'United States of America', 'lat': 40.7142, 'lon': -74.0064, 'tz_id': 'America/New_York', 'localtime_epoch': 1747724470, 'localtime': '2025-05-20 03:01'}, 'current': {'last_updated_epoch': 1747724400, 'last_updated': '2025-05-20 03:00', 'temp_c': 10.4, 'temp_f': 50.7, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 11.2, 'wind_kph': 18.0, 'wind_degree': 318, 'wind_dir': 'NW', 'pressure_mb': 1014.0, 'pressure_in': 29.94, '\u001b[0mExtract current temperature is not a valid tool, try one of [tavily_search_results_json].\u001b[32;1m\u001b[1;3mI should use a search engine to find the answer\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"weather in New York\"\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New York', 'region': 'New York', 'country': 'United States of America', 'lat': 40.7142, 'lon': -74.0064, 'tz_id': 'America/New_York', 'localtime_epoch': 1747724470, 'localtime': '2025-05-20 03:01'}, 'current': {'last_updated_epoch': 1747724400, 'last_updated': '2025-05-20 03:00', 'temp_c': 10.4, 'temp_f': 50.7, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 11.2, 'wind_kph': 18.0, 'wind_degree': 318, 'wind_dir': 'NW', 'pressure_mb': 1014.0, 'pressure_in': 29.94, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 58, 'cloud': 0, 'feelslike_c': 8.1, 'feelslike_f': 46.5, 'windchill_c': 6.2, 'windchill_f': 43.2, 'heatindex_c': 8.4, 'heatindex_f': 47.1, 'dewpoint_c': 4.7, 'dewpoint_f': 40.5, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 15.3, 'gust_kph': 24.6}}\"}]\u001b[0m\u001b[32;1m\u001b[1;3m I should extract the current temperature\n",
      "Action: Extract current temperature\n",
      "Action Input: [{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New York', 'region': 'New York', 'country': 'United States of America', 'lat': 40.7142, 'lon': -74.0064, 'tz_id': 'America/New_York', 'localtime_epoch': 1747724470, 'localtime': '2025-05-20 03:01'}, 'current': {'last_updated_epoch': 1747724400, 'last_updated': '2025-05-20 03:00', 'temp_c': 10.4, 'temp_f': 50.7, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 11.2, 'wind_kph': 18.0, 'wind_degree': 318, 'wind_dir': 'NW', 'pressure_mb': 1014.0, 'pressure_in': 29.94, '\u001b[0mExtract current temperature is not a valid tool, try one of [tavily_search_results_json].\u001b[32;1m\u001b[1;3m I should use a search engine to find the answer\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"weather in New York\"\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New York', 'region': 'New York', 'country': 'United States of America', 'lat': 40.7142, 'lon': -74.0064, 'tz_id': 'America/New_York', 'localtime_epoch': 1747724470, 'localtime': '2025-05-20 03:01'}, 'current': {'last_updated_epoch': 1747724400, 'last_updated': '2025-05-20 03:00', 'temp_c': 10.4, 'temp_f': 50.7, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 11.2, 'wind_kph': 18.0, 'wind_degree': 318, 'wind_dir': 'NW', 'pressure_mb': 1014.0, 'pressure_in': 29.94, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 58, 'cloud': 0, 'feelslike_c': 8.1, 'feelslike_f': 46.5, 'windchill_c': 6.2, 'windchill_f': 43.2, 'heatindex_c': 8.4, 'heatindex_f': 47.1, 'dewpoint_c': 4.7, 'dewpoint_f': 40.5, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 15.3, 'gust_kph': 24.6}}\"}]\u001b[0m\u001b[32;1m\u001b[1;3m I should extract the current temperature\n",
      "Action: Extract current temperature\n",
      "Action Input: [{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New York', 'region': 'New York', 'country': 'United States of America', 'lat': 40.7142, 'lon': -74.0064, 'tz_id': 'America/New_York', 'localtime_epoch': 1747724470, 'localtime': '2025-05-20 03:01'}, 'current': {'last_updated_epoch': 1747724400, 'last_updated': '2025-05-20 03:00', 'temp_c': 10.4, 'temp_f': 50.7, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 11.2, 'wind_kph': 18.0, 'wind_degree': 318, 'wind_dir': 'NW', 'pressure_mb': 1014.0, 'pressure_in': 29.94, '\n",
      "\u001b[0mExtract current temperature is not a valid tool, try one of [tavily_search_results_json].\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The current temperature in New York is 10.4 degrees Celsius or 50.7 degrees Fahrenheit.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the weather in New York?', 'output': 'The current temperature in New York is 10.4 degrees Celsius or 50.7 degrees Fahrenheit.'}\n"
     ]
    }
   ],
   "source": [
    "# react example\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Initialize tools\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "\n",
    "# Create prompt (can be customized)\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Set up the language model (LLM)\n",
    "llm = OpenAI()\n",
    "\n",
    "# Create the ReAct agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Initialize the agent executor with verbose logging\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Run the agent with an input\n",
    "response = agent_executor.invoke({\"input\": \"What is the weather in New York?\"})\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'LangChain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://en.wikipedia.org/wiki/LangChain', 'content': 'In October 2023 LangChain introduced LangServe, a deployment tool designed to facilitate the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[6] to store and retrieve vector embeddings; Weaviate vector database[7] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered popularity, with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project\\'s Discord server, many YouTube tutorials, and meetups in San Francisco and London. As of April 2023, it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal links[edit]'}]\u001b[0m\u001b[32;1m\u001b[1;3mLangChain is a project that was launched in October 2022 as an open-source initiative by Harrison Chase, who was working at machine learning startup Robust Intelligence. In April 2023, LangChain was officially incorporated as a startup and received over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, following a $10 million seed investment from Benchmark. \n",
      "\n",
      "LangChain introduced LangServe in October 2023, which is a deployment tool aimed at easing the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications. The project has gained significant popularity with contributions from numerous GitHub contributors, trending discussions on Twitter, active engagement on Discord, various YouTube tutorials, and meetups in San Francisco and London.\n",
      "\n",
      "LangChain offers integrations with various systems such as Amazon, Google, and Microsoft Azure cloud storage, API wrappers for news, movies, weather, Bash for summarization and execution of shell scripts, web scraping subsystems, few-shot learning prompt generation, Google Drive integration, language models like OpenAI, Anthropic, and Hugging Face, PDF text extraction tools, Python and JavaScript code generation, Milvus and Weaviate vector databases, SQL and NoSQL databases, Streamlit for logging, and more.\n",
      "\n",
      "For more detailed information, you can visit the [Wikipedia page on LangChain](https://en.wikipedia.org/wiki/LangChain).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is LangChain?', 'output': 'LangChain is a project that was launched in October 2022 as an open-source initiative by Harrison Chase, who was working at machine learning startup Robust Intelligence. In April 2023, LangChain was officially incorporated as a startup and received over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, following a $10 million seed investment from Benchmark. \\n\\nLangChain introduced LangServe in October 2023, which is a deployment tool aimed at easing the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications. The project has gained significant popularity with contributions from numerous GitHub contributors, trending discussions on Twitter, active engagement on Discord, various YouTube tutorials, and meetups in San Francisco and London.\\n\\nLangChain offers integrations with various systems such as Amazon, Google, and Microsoft Azure cloud storage, API wrappers for news, movies, weather, Bash for summarization and execution of shell scripts, web scraping subsystems, few-shot learning prompt generation, Google Drive integration, language models like OpenAI, Anthropic, and Hugging Face, PDF text extraction tools, Python and JavaScript code generation, Milvus and Weaviate vector databases, SQL and NoSQL databases, Streamlit for logging, and more.\\n\\nFor more detailed information, you can visit the [Wikipedia page on LangChain](https://en.wikipedia.org/wiki/LangChain).'}\n"
     ]
    }
   ],
   "source": [
    "# tool calling example\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Initialize tools (e.g., search tool)\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "\n",
    "# Define prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Use the tavily_search_results_json tool for information.\"),\n",
    "    (\"placeholder\", \"{chat_history}\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "# Set up LLM model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# Create tool-calling agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# Set up the agent executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Run the agent\n",
    "response = agent_executor.invoke({\"input\": \"What is LangChain?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ReAct agent is ideal for tasks that involve both reasoning and acting. It can break down tasks into smaller steps and interact with tools iteratively, often combining multiple reasoning steps with tool usage.\n",
    "\n",
    "On the other hand, Tool Calling agents are more suited for tasks that rely on external tools directly, using them to obtain specific data or take actions. These agents excel in situations where the tool provides direct answers or solutions.\n",
    "\n",
    "Use Tool Calling when you need precise tool interactions for data retrieval, and ReAct when the task requires deeper analysis or multi-step reasoning before tool usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "This introduction covered the basics of LangChain agents, including their components, applications, and a simple implementation. In the next notebook, we'll:\n",
    "- Explore advanced agents.\n",
    "- Implement agents with LangGraph.\n",
    "- Debug and optimize agent workflows.\n",
    "\n",
    "Stay tuned for more examples and in-depth explanations!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
